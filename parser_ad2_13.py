#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ÿæÿßÿ±ÿ≥ÿ± ÿØŸÇ€åŸÇ ÿ®ÿ±ÿß€å AD 2.13 - DECLARED DISTANCES
ÿß€åŸÜ ÿ¨ÿØŸàŸÑ ŸÖŸÖ⁄©ŸÜ ÿßÿ≥ÿ™ ⁄ÜŸÜÿØ ÿµŸÅÿ≠Ÿá‚Äåÿß€å ÿ®ÿßÿ¥ÿØ Ÿà Ÿáÿ± ÿ®ÿßŸÜÿØ ŸÖ€å‚Äåÿ™ŸàÿßŸÜÿØ ⁄ÜŸÜÿØ€åŸÜ ÿ±ÿØ€åŸÅ ÿØÿßÿ¥ÿ™Ÿá ÿ®ÿßÿ¥ÿØ

ÿ≥ÿßÿÆÿ™ÿßÿ± ÿ¨ÿØŸàŸÑ:
1. RWY Designator - ÿ¥ŸÖÿßÿ±Ÿá ÿ®ÿßŸÜÿØ
2. TORA (M) - Take-Off Run Available
3. TODA (M) - Take-Off Distance Available
4. ASDA (M) - Accelerate-Stop Distance Available
5. LDA (M) - Landing Distance Available
6. Remarks - ÿ™Ÿàÿ∂€åÿ≠ÿßÿ™

ÿÆÿ±Ÿàÿ¨€å: ÿØÿßÿØŸá‚ÄåŸáÿß ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿ®ÿßŸÜÿØ cluster ŸÖ€å‚Äåÿ¥ŸàŸÜÿØ
"""

import json
import re
import sys
from pathlib import Path
import pdfplumber


def deep_clean_text(text: str) -> str:
    """
    ÿ™ŸÖ€åÿ≤ ⁄©ÿ±ÿØŸÜ ÿπŸÖ€åŸÇ ŸÖÿ™ŸÜ - ÿ≠ÿ∞ŸÅ ŸáŸÖŸá ⁄©ÿßÿ±ÿß⁄©ÿ™ÿ±Ÿáÿß€å ÿ∫€åÿ±ÿπÿßÿØ€å
    ŸÅŸÇÿ∑ ÿ≠ÿ±ŸàŸÅÿå ÿßÿπÿØÿßÿØÿå ŸÅÿßÿµŸÑŸá Ÿà ⁄ÜŸÜÿØ ⁄©ÿßÿ±ÿß⁄©ÿ™ÿ± ÿ∂ÿ±Ÿàÿ±€å ŸÜ⁄ØŸá ÿØÿßÿ¥ÿ™Ÿá ŸÖ€å‚Äåÿ¥ŸàÿØ
    """
    if not text:
        return ""
    
    text = str(text)
    
    # 1. ÿ≠ÿ∞ŸÅ ŸáŸÖŸá Unicode Private Use Area characters
    text = re.sub(r'[\ue000-\uf8ff]', '', text)
    
    # 2. ÿ≠ÿ∞ŸÅ ŸáŸÖŸá Unicode symbols Ÿà arrows
    text = re.sub(r'[\u2190-\u21ff]', '', text)  # Arrows
    text = re.sub(r'[\u2500-\u257f]', '', text)  # Box Drawing
    text = re.sub(r'[\u2580-\u259f]', '', text)  # Block Elements
    text = re.sub(r'[\u25a0-\u25ff]', '', text)  # Geometric Shapes
    text = re.sub(r'[\u2600-\u26ff]', '', text)  # Miscellaneous Symbols
    text = re.sub(r'[\u2700-\u27bf]', '', text)  # Dingbats
    
    # 3. ÿ≠ÿ∞ŸÅ degree symbols
    text = re.sub(r'[\u00b0\u00ba]', '', text)
    
    # 4. ÿ≠ÿ∞ŸÅ control characters
    text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f-\x9f]', '', text)
    
    # 5. ŸÅŸÇÿ∑ ÿ≠ÿ±ŸàŸÅÿå ÿßÿπÿØÿßÿØÿå ŸÅÿßÿµŸÑŸáÿå newline Ÿà ⁄ÜŸÜÿØ ⁄©ÿßÿ±ÿß⁄©ÿ™ÿ± ÿ∂ÿ±Ÿàÿ±€å ŸÜ⁄ØŸá ÿØÿßÿ±
    text = re.sub(r'[^\w\s\n/.()%:,x+-]', '', text, flags=re.IGNORECASE)
    
    return text


def clean_value(text: str):
    """ÿ™ŸÖ€åÿ≤ ⁄©ÿ±ÿØŸÜ ŸÖŸÇÿØÿßÿ± ÿ®ÿ±ÿß€å ÿÆÿ±Ÿàÿ¨€å JSON - Case sensitive"""
    if not text:
        return None
    
    text = deep_clean_text(text).strip()
    
    # ÿ™ÿ®ÿØ€åŸÑ NIL ÿ®Ÿá None (case insensitive)
    if text.upper() == "NIL":
        return None
    
    # ÿ™ŸÖ€åÿ≤ ⁄©ÿ±ÿØŸÜ ŸÅÿßÿµŸÑŸá‚ÄåŸáÿß€å ÿßÿ∂ÿßŸÅ€å
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text if text else None


def clean_text_for_parsing(text: str) -> str:
    """ÿ™ŸÖ€åÿ≤ ⁄©ÿ±ÿØŸÜ ŸÖÿ™ŸÜ ÿ®ÿ±ÿß€å Ÿæÿßÿ±ÿ≥€åŸÜ⁄Ø"""
    return deep_clean_text(text)


def extract_ad2_13(pdf_path: str) -> list:
    """
    ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ÿØŸÇ€åŸÇ ÿØÿßÿØŸá‚ÄåŸáÿß€å AD 2.13 ÿßÿ≤ PDF
    Ÿæÿ¥ÿ™€åÿ®ÿßŸÜ€å ÿßÿ≤ ÿ¨ÿØŸàŸÑ‚ÄåŸáÿß€å ⁄ÜŸÜÿØ ÿµŸÅÿ≠Ÿá‚Äåÿß€å
    
    Returns:
        list: ÿ¢ÿ±ÿß€åŸá‚Äåÿß€å ÿßÿ≤ ÿ±⁄©Ÿàÿ±ÿØŸáÿß€å ÿ®ÿßŸÜÿØŸáÿß ÿ®ÿß cluster ÿ¥ÿØŸá
    """
    result = []
    
    print(f"üîç ÿØÿ± ÿ≠ÿßŸÑ ÿ¨ÿ≥ÿ™ÿ¨Ÿà€å AD 2.13 ÿØÿ± PDF: {pdf_path}")
    
    with pdfplumber.open(pdf_path) as pdf:
        # Ÿæ€åÿØÿß ⁄©ÿ±ÿØŸÜ ŸáŸÖŸá ÿµŸÅÿ≠ÿßÿ™ ŸÖÿ±ÿ®Ÿàÿ∑ ÿ®Ÿá AD 2.13
        ad2_13_pages = []
        ad2_13_started = False
        
        for page_num, page in enumerate(pdf.pages):
            text = page.extract_text()
            
            if not text:
                continue
            
            # ÿ®ÿ±ÿ±ÿ≥€å ÿ¥ÿ±Ÿàÿπ AD 2.13
            if "AD 2.13" in text or "AD2.13" in text:
                ad2_13_started = True
                ad2_13_pages.append((page_num, text))
                print(f"‚úÖ ÿµŸÅÿ≠Ÿá {page_num + 1} Ÿæ€åÿØÿß ÿ¥ÿØ: AD 2.13 (ÿ¥ÿ±Ÿàÿπ)")
            
            # ÿ®ÿ±ÿ±ÿ≥€å ÿßÿØÿßŸÖŸá ÿ¨ÿØŸàŸÑ ÿØÿ± ÿµŸÅÿ≠ÿßÿ™ ÿ®ÿπÿØ€å
            elif ad2_13_started:
                # ÿß⁄Øÿ± ÿ®Ÿá AD 2.14 €åÿß ÿ®ÿÆÿ¥ ÿØ€å⁄Øÿ±€å ÿ±ÿ≥€åÿØ€åŸÖÿå Ÿæÿß€åÿßŸÜ
                if "AD 2.14" in text or "AD2.14" in text:
                    # ŸÖŸÖ⁄©ŸÜ ÿßÿ≥ÿ™ ÿ®ÿÆÿ¥€å ÿßÿ≤ AD 2.13 ÿØÿ± ŸáŸÖ€åŸÜ ÿµŸÅÿ≠Ÿá ÿ®ÿßÿ¥ÿØ
                    ad2_13_pages.append((page_num, text))
                    print(f"‚úÖ ÿµŸÅÿ≠Ÿá {page_num + 1} Ÿæ€åÿØÿß ÿ¥ÿØ: AD 2.13 (Ÿæÿß€åÿßŸÜ)")
                    break
                
                # ÿ®ÿ±ÿ±ÿ≥€å ÿßÿØÿßŸÖŸá ÿ¨ÿØŸàŸÑ
                if is_continuation_page(text):
                    ad2_13_pages.append((page_num, text))
                    print(f"‚úÖ ÿµŸÅÿ≠Ÿá {page_num + 1} Ÿæ€åÿØÿß ÿ¥ÿØ: AD 2.13 (ÿßÿØÿßŸÖŸá)")
                else:
                    break
        
        if not ad2_13_pages:
            print("‚ùå ÿµŸÅÿ≠Ÿá‚Äåÿß€å ÿ®ÿ±ÿß€å AD 2.13 Ÿæ€åÿØÿß ŸÜÿ¥ÿØ")
            return result
        
        print(f"üìÑ ÿ™ÿπÿØÿßÿØ ÿµŸÅÿ≠ÿßÿ™ AD 2.13: {len(ad2_13_pages)}")
        
        # ÿ™ÿ±⁄©€åÿ® ŸÖÿ™ŸÜ ŸáŸÖŸá ÿµŸÅÿ≠ÿßÿ™
        combined_text = combine_pages_text(ad2_13_pages)
        
        # ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ÿØÿßÿØŸá‚ÄåŸáÿß
        result = parse_ad2_13_text(combined_text)
    
    return result


def is_continuation_page(text: str) -> bool:
    """ÿ®ÿ±ÿ±ÿ≥€å ÿß€åŸÜ⁄©Ÿá ÿ¢€åÿß ÿµŸÅÿ≠Ÿá ÿßÿØÿßŸÖŸá ÿ¨ÿØŸàŸÑ AD 2.13 ÿßÿ≥ÿ™"""
    text_upper = text.upper()
    
    # ÿßŸÑ⁄ØŸàŸáÿß€å ÿßÿØÿßŸÖŸá ÿ¨ÿØŸàŸÑ
    continuation_indicators = [
        # ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ®ÿßŸÜÿØ
        r'\b(\d{2}[LRCM]?)\b',
        # header Ÿáÿß€å ÿ¨ÿØŸàŸÑ
        "RWY",
        "DESIGNATOR",
        "TORA",
        "TODA",
        "ASDA",
        "LDA",
        "REMARKS",
        "DECLARED DISTANCES",
    ]
    
    for indicator in continuation_indicators:
        if indicator.startswith(r'\b'):
            if re.search(indicator, text, re.IGNORECASE):
                return True
        else:
            if indicator in text_upper:
                return True
    
    return False


def combine_pages_text(pages: list) -> str:
    """ÿ™ÿ±⁄©€åÿ® ŸÖÿ™ŸÜ ÿµŸÅÿ≠ÿßÿ™"""
    combined_parts = []
    
    for page_num, text in pages:
        text = clean_text_for_parsing(text)
        
        # ÿ≠ÿ∞ŸÅ header Ÿà footer
        lines = text.split('\n')
        filtered_lines = []
        
        for line in lines:
            line_upper = line.upper().strip()
            
            # ÿ≠ÿ∞ŸÅ header/footer
            if any(skip in line_upper for skip in [
                "CIVIL AVIATION ORGANIZATION",
                "AIRAC AMDT",
                "AIP",
                "ISLAMIC REPUBLIC OF IRAN",
            ]):
                continue
            
            # ÿ≠ÿ∞ŸÅ ÿ¥ŸÖÿßÿ±Ÿá ÿµŸÅÿ≠Ÿá
            if re.match(r'^AD\s*2-\d+\s*OIII', line_upper):
                continue
            if re.match(r'^WEF\s+\d+\s+\w+\s+\d+', line_upper):
                continue
            
            filtered_lines.append(line)
        
        combined_parts.append('\n'.join(filtered_lines))
    
    return '\n'.join(combined_parts)


def parse_ad2_13_text(text: str) -> list:
    """
    Parse ÿØŸÇ€åŸÇ ŸÖÿ™ŸÜ AD 2.13
    ÿÆÿ±Ÿàÿ¨€å: ŸÑ€åÿ≥ÿ™ ÿ®ÿßŸÜÿØŸáÿß ÿ®ÿß entries ÿ®ÿ±ÿß€å Ÿáÿ± ÿ®ÿßŸÜÿØ
    """
    runways_dict = {}  # ⁄©ŸÑ€åÿØ: ÿ¥ŸÖÿßÿ±Ÿá ÿ®ÿßŸÜÿØÿå ŸÖŸÇÿØÿßÿ±: ŸÑ€åÿ≥ÿ™ entries
    
    text = clean_text_for_parsing(text)
    
    # Ÿæ€åÿØÿß ⁄©ÿ±ÿØŸÜ ÿ®ÿÆÿ¥ AD 2.13
    start_idx = text.find("AD 2.13")
    if start_idx == -1:
        start_idx = 0
    
    # Ÿæ€åÿØÿß ⁄©ÿ±ÿØŸÜ Ÿæÿß€åÿßŸÜ ÿ®ÿÆÿ¥
    end_idx = text.find("AD 2.14", start_idx)
    if end_idx == -1:
        end_idx = len(text)
    
    ad2_13_text = text[start_idx:end_idx]
    
    # ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ Ÿàÿßÿ≠ÿØŸáÿß ÿßÿ≤ header
    units = extract_units_from_headers(ad2_13_text)
    
    # ÿ™ŸÇÿ≥€åŸÖ ÿ®Ÿá ÿÆÿ∑Ÿàÿ∑
    lines = ad2_13_text.split('\n')
    
    # ÿßŸÑ⁄ØŸà€å ÿ±ÿØ€åŸÅ ÿØÿßÿØŸá:
    # RWY_NR TORA TODA ASDA LDA [Remarks]
    # ŸÖÿ´ÿßŸÑ: 11L 3646 3646 3646 2796 NIL
    # €åÿß: 29L 3640 3640 3640 NIL Take-off from intersection with U
    
    # ÿßŸÑ⁄ØŸà€å ÿßÿµŸÑ€å: ÿ¥ŸÖÿßÿ±Ÿá ÿ®ÿßŸÜÿØ + 4 ÿπÿØÿØ + (NIL €åÿß ÿ™Ÿàÿ∂€åÿ≠ÿßÿ™)
    row_pattern = r'^(\d{2}[LRCM]?)\s+(\d+)\s+(\d+)\s+(\d+)\s+(\d+|NIL)\s*(.*?)$'
    
    # ÿßŸÑ⁄ØŸà€å ÿ±ÿØ€åŸÅ ÿ®ÿØŸàŸÜ ÿ¥ŸÖÿßÿ±Ÿá ÿ®ÿßŸÜÿØ (ÿßÿØÿßŸÖŸá ÿ®ÿßŸÜÿØ ŸÇÿ®ŸÑ€å)
    # ŸÖÿ´ÿßŸÑ: 3544 3544 3544 NIL Take-off from intersection with A2
    continuation_pattern = r'^(\d+)\s+(\d+)\s+(\d+)\s+(\d+|NIL)\s*(.*?)$'
    
    current_rwy = None
    
    for line in lines:
        line = line.strip()
        
        if not line:
            continue
        
        # ÿ®ÿ±ÿ±ÿ≥€å ÿ±ÿØ€åŸÅ ÿ®ÿß ÿ¥ŸÖÿßÿ±Ÿá ÿ®ÿßŸÜÿØ
        match = re.match(row_pattern, line, re.IGNORECASE)
        if match:
            rwy_nr = match.group(1).upper()
            tora = clean_value(match.group(2))
            toda = clean_value(match.group(3))
            asda = clean_value(match.group(4))
            lda = clean_value(match.group(5))
            remarks = clean_value(match.group(6)) if match.group(6) else None
            
            current_rwy = rwy_nr
            
            # ÿ≥ÿßÿÆÿ™ entry
            entry = {
                "TORA": tora,
                "TODA": toda,
                "ASDA": asda,
                "LDA": lda,
                "Remarks": remarks,
            }
            
            # ÿßÿ∂ÿßŸÅŸá ⁄©ÿ±ÿØŸÜ Ÿàÿßÿ≠ÿØŸáÿß
            if tora is not None:
                entry["TORA_unit"] = units.get("TORA", "M")
            if toda is not None:
                entry["TODA_unit"] = units.get("TODA", "M")
            if asda is not None:
                entry["ASDA_unit"] = units.get("ASDA", "M")
            if lda is not None:
                entry["LDA_unit"] = units.get("LDA", "M")
            
            # ÿßÿ∂ÿßŸÅŸá ⁄©ÿ±ÿØŸÜ ÿ®Ÿá dict
            if rwy_nr not in runways_dict:
                runways_dict[rwy_nr] = []
            runways_dict[rwy_nr].append(entry)
            
            print(f"  ‚úì ÿ®ÿßŸÜÿØ {rwy_nr} Ÿæ€åÿØÿß ÿ¥ÿØ")
            continue
        
        # ÿ®ÿ±ÿ±ÿ≥€å ÿ±ÿØ€åŸÅ ÿßÿØÿßŸÖŸá (ÿ®ÿØŸàŸÜ ÿ¥ŸÖÿßÿ±Ÿá ÿ®ÿßŸÜÿØ)
        if current_rwy:
            cont_match = re.match(continuation_pattern, line, re.IGNORECASE)
            if cont_match:
                tora = clean_value(cont_match.group(1))
                toda = clean_value(cont_match.group(2))
                asda = clean_value(cont_match.group(3))
                lda = clean_value(cont_match.group(4))
                remarks = clean_value(cont_match.group(5)) if cont_match.group(5) else None
                
                entry = {
                    "TORA": tora,
                    "TODA": toda,
                    "ASDA": asda,
                    "LDA": lda,
                    "Remarks": remarks,
                }
                
                # ÿßÿ∂ÿßŸÅŸá ⁄©ÿ±ÿØŸÜ Ÿàÿßÿ≠ÿØŸáÿß
                if tora is not None:
                    entry["TORA_unit"] = units.get("TORA", "M")
                if toda is not None:
                    entry["TODA_unit"] = units.get("TODA", "M")
                if asda is not None:
                    entry["ASDA_unit"] = units.get("ASDA", "M")
                if lda is not None:
                    entry["LDA_unit"] = units.get("LDA", "M")
                
                runways_dict[current_rwy].append(entry)
                print(f"  ‚úì ÿßÿØÿßŸÖŸá ÿ®ÿßŸÜÿØ {current_rwy} Ÿæ€åÿØÿß ÿ¥ÿØ")
    
    # ÿ™ÿ®ÿØ€åŸÑ ÿ®Ÿá ŸÑ€åÿ≥ÿ™ ÿÆÿ±Ÿàÿ¨€å ÿ®ÿß ÿ™ÿ±ÿ™€åÿ® ÿµÿ≠€åÿ≠
    result = []
    
    # ŸÖÿ±ÿ™ÿ®‚Äåÿ≥ÿßÿ≤€å ÿ®ÿßŸÜÿØŸáÿß
    sorted_rwys = sorted(runways_dict.keys(), key=lambda x: (int(re.search(r'\d+', x).group()), x))
    
    for rwy_nr in sorted_rwys:
        entries = runways_dict[rwy_nr]
        
        # ŸÖÿ±ÿ™ÿ® ⁄©ÿ±ÿØŸÜ ŸÅ€åŸÑÿØŸáÿß ÿØÿ± Ÿáÿ± entry
        ordered_entries = []
        for entry in entries:
            ordered_entry = {}
            field_order = ["TORA", "TORA_unit", "TODA", "TODA_unit", 
                          "ASDA", "ASDA_unit", "LDA", "LDA_unit", "Remarks"]
            
            for field in field_order:
                if field in entry:
                    ordered_entry[field] = entry[field]
            
            ordered_entries.append(ordered_entry)
        
        result.append({
            "RWY Designator": rwy_nr,
            "entries": ordered_entries
        })
    
    return result


def extract_units_from_headers(text: str) -> dict:
    """ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ Ÿàÿßÿ≠ÿØŸáÿß ÿßÿ≤ header Ÿáÿß€å ÿ¨ÿØŸàŸÑ (Case sensitive)"""
    units = {}
    
    # ÿßŸÑ⁄ØŸàŸáÿß€å Ÿàÿßÿ≠ÿØ
    unit_patterns = {
        "TORA": r"TORA\s*\(([A-Za-z]+)\)",
        "TODA": r"TODA\s*\(([A-Za-z]+)\)",
        "ASDA": r"ASDA\s*\(([A-Za-z]+)\)",
        "LDA": r"LDA\s*\(([A-Za-z]+)\)",
    }
    
    for field_name, pattern in unit_patterns.items():
        match = re.search(pattern, text)
        if match:
            units[field_name] = match.group(1)
    
    # ŸÖŸÇÿßÿØ€åÿ± Ÿæ€åÿ¥‚ÄåŸÅÿ±ÿ∂
    default_units = {
        "TORA": "M",
        "TODA": "M",
        "ASDA": "M",
        "LDA": "M",
    }
    
    for field_name, default_unit in default_units.items():
        if field_name not in units:
            units[field_name] = default_unit
    
    return units


def main():
    """ÿ™ÿßÿ®ÿπ ÿßÿµŸÑ€å"""
    if len(sys.argv) > 1:
        pdf_path = sys.argv[1]
    else:
        pdf_path = "OIII.pdf"
    
    if not Path(pdf_path).exists():
        print(f"‚ùå ŸÅÿß€åŸÑ PDF €åÿßŸÅÿ™ ŸÜÿ¥ÿØ: {pdf_path}")
        sys.exit(1)
    
    # ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ÿØÿßÿØŸá‚ÄåŸáÿß
    try:
        data = extract_ad2_13(pdf_path)
        
        if not data:
            print("‚ùå Ÿá€å⁄Ü ÿØÿßÿØŸá‚Äåÿß€å ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ŸÜÿ¥ÿØ!")
            sys.exit(1)
        
        # ÿ∞ÿÆ€åÿ±Ÿá ÿØÿ± ŸÅÿß€åŸÑ JSON
        output_path = "ad2_13_output.json"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"\n‚úÖ ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ÿ®ÿß ŸÖŸàŸÅŸÇ€åÿ™ ÿßŸÜÿ¨ÿßŸÖ ÿ¥ÿØ!")
        print(f"üìÅ ŸÅÿß€åŸÑ ÿÆÿ±Ÿàÿ¨€å: {output_path}")
        print(f"üìä ÿ™ÿπÿØÿßÿØ ÿ®ÿßŸÜÿØŸáÿß€å ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ÿ¥ÿØŸá: {len(data)}")
        
        # ŸÜŸÖÿß€åÿ¥ ÿÆŸÑÿßÿµŸá
        total_entries = sum(len(rwy['entries']) for rwy in data)
        print(f"üìã ŸÖÿ¨ŸÖŸàÿπ entries: {total_entries}")
        
        print("\nüìã ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ÿ¥ÿØŸá:")
        for rwy in data:
            print(f"\n  ÿ®ÿßŸÜÿØ {rwy['RWY Designator']} ({len(rwy['entries'])} entry):")
            for i, entry in enumerate(rwy['entries'], 1):
                remarks = entry.get('Remarks')
                remarks_display = "null" if remarks is None else (remarks[:40] + "..." if len(remarks) > 40 else remarks)
                tora = entry['TORA'] if entry['TORA'] is not None else "null"
                toda = entry['TODA'] if entry['TODA'] is not None else "null"
                asda = entry['ASDA'] if entry['ASDA'] is not None else "null"
                lda = entry['LDA'] if entry['LDA'] is not None else "null"
                print(f"    {i}. TORA={tora}, TODA={toda}, ASDA={asda}, LDA={lda}, Remarks={remarks_display}")
        
    except Exception as e:
        print(f"\n‚ùå ÿÆÿ∑ÿß ÿØÿ± Ÿæÿ±ÿØÿßÿ≤ÿ¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

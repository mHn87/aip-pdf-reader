#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ูพุงุฑุณุฑ ุฏูู ุจุฑุง AD 2.12 - RUNWAY PHYSICAL CHARACTERISTICS
ุงู ุฌุฏูู ุฏุงุฑุง ุณุชููโูุง ุนููุฏ ุงุณุช ู ููุดู ุฏู ุชฺฉู ุงุณุช (6 ุณุชูู ุงูู + 6 ุณุชูู ุจุนุฏ)

ุณุงุฎุชุงุฑ ุฌุฏูู:
ุจุฎุด ุงูู (ุณุชููโูุง 1-6):
1. Designations RWY NR
2. TRUE BRG
3. Dimensions of RWY (M)
4. Strength (PCR or PCN) and surface of RWY and SWY
5. THR coordinates THR geoid undulation
6. THR elevation and highest elevation of TDZ of precision APP RWY

ุจุฎุด ุฏูู (ุณุชููโูุง 7-12):
7. Slope of RWY - SWY
8. SWY dimensions (M)
9. CWY dimensions (M)
10. Strip dimensions (M)
11. RESA (M)
12. OFZ
"""

import json
import re
import sys
from pathlib import Path
import pdfplumber


def deep_clean_text(text: str) -> str:
    """
    ุชูุฒ ฺฉุฑุฏู ุนูู ูุชู - ุญุฐู ููู ฺฉุงุฑุงฺฉุชุฑูุง ุบุฑุนุงุฏ
    ููุท ุญุฑููุ ุงุนุฏุงุฏุ ูุงุตูู ู ฺูุฏ ฺฉุงุฑุงฺฉุชุฑ ุถุฑูุฑ ูฺฏู ุฏุงุดุชู ูโุดูุฏ
    """
    if not text:
        return ""
    
    text = str(text)
    
    # 1. ุญุฐู ููู Unicode Private Use Area characters
    text = re.sub(r'[\ue000-\uf8ff]', '', text)
    
    # 2. ุญุฐู ููู Unicode symbols ู arrows
    text = re.sub(r'[\u2190-\u21ff]', '', text)  # Arrows
    text = re.sub(r'[\u2500-\u257f]', '', text)  # Box Drawing
    text = re.sub(r'[\u2580-\u259f]', '', text)  # Block Elements
    text = re.sub(r'[\u25a0-\u25ff]', '', text)  # Geometric Shapes
    text = re.sub(r'[\u2600-\u26ff]', '', text)  # Miscellaneous Symbols
    text = re.sub(r'[\u2700-\u27bf]', '', text)  # Dingbats
    
    # 3. ุญุฐู degree symbols
    text = re.sub(r'[\u00b0\u00ba]', '', text)
    
    # 4. ุญุฐู control characters
    text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f-\x9f]', '', text)
    
    # 5. ููุท ุญุฑููุ ุงุนุฏุงุฏุ ูุงุตููุ newline ู ฺูุฏ ฺฉุงุฑุงฺฉุชุฑ ุถุฑูุฑ ูฺฏู ุฏุงุฑ
    # ุถุฑูุฑ: / . ( ) - + % : , x X
    text = re.sub(r'[^\w\s\n/.()%:,x+-]', '', text, flags=re.IGNORECASE)
    
    return text


def clean_value(text: str):
    """ุชูุฒ ฺฉุฑุฏู ููุฏุงุฑ ุจุฑุง ุฎุฑูุฌ JSON - Case sensitive"""
    if not text:
        return None
    
    text = deep_clean_text(text).strip()
    
    # ุชุจุฏู NIL ุจู None (case insensitive)
    if text.upper() == "NIL":
        return None
    
    # ุชูุฒ ฺฉุฑุฏู ูุงุตููโูุง ุงุถุงู
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text if text else None


def clean_text_for_parsing(text: str) -> str:
    """ุชูุฒ ฺฉุฑุฏู ูุชู ุจุฑุง ูพุงุฑุณูฺฏ"""
    return deep_clean_text(text)


def extract_ad2_12(pdf_path: str) -> list:
    """
    ุงุณุชุฎุฑุงุฌ ุฏูู ุฏุงุฏูโูุง AD 2.12 ุงุฒ PDF
    ูพุดุชุจุงู ุงุฒ ุฌุฏููโูุง ฺูุฏ ุตูุญูโุง
    
    Returns:
        list: ุขุฑุงูโุง ุงุฒ ุฑฺฉูุฑุฏูุง ุจุงูุฏูุง
    """
    result = []
    
    print(f"๐ ุฏุฑ ุญุงู ุฌุณุชุฌู AD 2.12 ุฏุฑ PDF: {pdf_path}")
    
    with pdfplumber.open(pdf_path) as pdf:
        # ุงุจุชุฏุง ููู ุตูุญุงุช ูุฑุจูุท ุจู AD 2.12 ุฑุง ูพุฏุง ูโฺฉูู
        ad2_12_pages = []
        ad2_12_started = False
        
        for page_num, page in enumerate(pdf.pages):
            text = page.extract_text()
            
            if not text:
                continue
            
            # ุจุฑุฑุณ ุดุฑูุน AD 2.12
            if "AD 2.12" in text or "AD2.12" in text:
                ad2_12_started = True
                ad2_12_pages.append((page_num, text))
                print(f"โ ุตูุญู {page_num + 1} ูพุฏุง ุดุฏ: AD 2.12 (ุดุฑูุน)")
            
            # ุจุฑุฑุณ ุงุฏุงูู ุฌุฏูู ุฏุฑ ุตูุญุงุช ุจุนุฏ
            elif ad2_12_started:
                # ุงฺฏุฑ ุจู AD 2.13 ุฑุณุฏูุ ูพุงุงู AD 2.12
                if "AD 2.13" in text or "AD2.13" in text:
                    # ููฺฉู ุงุณุช ุจุฎุด ุงุฒ AD 2.12 ุฏุฑ ููู ุตูุญู ุจุงุดุฏ
                    ad2_12_pages.append((page_num, text))
                    print(f"โ ุตูุญู {page_num + 1} ูพุฏุง ุดุฏ: AD 2.12 (ูพุงุงู)")
                    break
                
                # ุจุฑุฑุณ ุงูฺฉู ุขุง ุงู ุตูุญู ุงุฏุงูู ุฌุฏูู ุงุณุช
                # ูุนูููุงู ุงุฏุงูู ุฌุฏูู ุดุงูู ุฏุงุฏูโูุง ุจุงูุฏ ุง header ูุง ุณุชูู ุงุณุช
                if is_continuation_page(text):
                    ad2_12_pages.append((page_num, text))
                    print(f"โ ุตูุญู {page_num + 1} ูพุฏุง ุดุฏ: AD 2.12 (ุงุฏุงูู)")
                else:
                    # ุงฺฏุฑ ุตูุญู ูุฑุจูุท ุจู AD 2.12 ูุณุชุ ูพุงุงู ุฌุฏูู
                    break
        
        if not ad2_12_pages:
            print("โ ุตูุญูโุง ุจุฑุง AD 2.12 ูพุฏุง ูุดุฏ")
            return result
        
        print(f"๐ ุชุนุฏุงุฏ ุตูุญุงุช AD 2.12: {len(ad2_12_pages)}")
        
        # ุชุฑฺฉุจ ูุชู ููู ุตูุญุงุช
        combined_text = combine_pages_text(ad2_12_pages)
        
        # ุงุณุชุฎุฑุงุฌ ุฏุงุฏูโูุง
        result = parse_ad2_12_text(combined_text)
    
    return result


def is_continuation_page(text: str) -> bool:
    """
    ุจุฑุฑุณ ุงูฺฉู ุขุง ุตูุญู ุงุฏุงูู ุฌุฏูู AD 2.12 ุงุณุช
    """
    text_upper = text.upper()
    
    # ุงูฺฏููุง ุงุฏุงูู ุฌุฏูู
    continuation_indicators = [
        # ุฏุงุฏูโูุง ุจุงูุฏ
        r'\b(11[LRC]|29[LRC]|0[1-9][LRC]|[1-3][0-9][LRC])\b',
        # header ูุง ุจุฎุด ุงูู
        "DESIGNATIONS",
        "TRUE BRG",
        "DIMENSIONS OF RWY",
        "THR COORDINATES",
        "THR ELEVATION",
        # header ูุง ุจุฎุด ุฏูู
        "SLOPE OF RWY",
        "SWY DIMENSIONS",
        "CWY DIMENSIONS",
        "STRIP DIMENSION",
        "RESA",
        "OFZ",
        # ุดูุงุฑู ุณุชููโูุง
        "1 2 3 4 5 6",
        "7 8 9 10 11 12",
    ]
    
    for indicator in continuation_indicators:
        if indicator.startswith(r'\b'):
            # ุงูฺฏู regex
            if re.search(indicator, text, re.IGNORECASE):
                return True
        else:
            # ูุชู ุณุงุฏู
            if indicator in text_upper:
                return True
    
    return False


def combine_pages_text(pages: list) -> str:
    """
    ุชุฑฺฉุจ ูุชู ุตูุญุงุช ุจุฑุง ูพุฑุฏุงุฒุด ฺฉูพุงุฑฺู
    """
    combined_parts = []
    
    for page_num, text in pages:
        # ุชูุฒ ฺฉุฑุฏู ูุชู
        text = clean_text_for_parsing(text)
        
        # ุญุฐู header ู footer ุตูุญุงุช (ูุนูููุงู ุดุงูู AIP, CIVIL AVIATION ู ุบุฑู)
        lines = text.split('\n')
        filtered_lines = []
        
        for line in lines:
            line_upper = line.upper().strip()
            
            # ุญุฐู header/footer
            if any(skip in line_upper for skip in [
                "CIVIL AVIATION ORGANIZATION",
                "AIRAC AMDT",
                "AIP",
                "ISLAMIC REPUBLIC OF IRAN",
            ]):
                continue
            
            # ุญุฐู ุดูุงุฑู ุตูุญู
            if re.match(r'^AD\s*2-\d+\s*OIII', line_upper):
                continue
            if re.match(r'^WEF\s+\d+\s+\w+\s+\d+', line_upper):
                continue
            
            filtered_lines.append(line)
        
        combined_parts.append('\n'.join(filtered_lines))
    
    return '\n'.join(combined_parts)


def parse_ad2_12_text(text: str) -> list:
    """
    Parse ุฏูู ูุชู AD 2.12 ุจุง ุฏุฑ ูุธุฑ ฺฏุฑ ุณุงุฎุชุงุฑ ุฏู ุชฺฉู
    ูพุดุชุจุงู ุงุฒ ุฌุฏููโูุง ฺูุฏ ุตูุญูโุง
    """
    runways_dict = {}  # ุงุณุชูุงุฏู ุงุฒ dict ุจุฑุง ุฌููฺฏุฑ ุงุฒ ุชฺฉุฑุงุฑ ุจุงูุฏูุง
    
    # ุชูุฒ ฺฉุฑุฏู ูุชู ุงุฒ ฺฉุงุฑุงฺฉุชุฑูุง ููฺฉุฏ ุฎุงุต
    text = clean_text_for_parsing(text)
    
    # ูพุฏุง ฺฉุฑุฏู ุจุฎุด AD 2.12
    start_idx = text.find("AD 2.12")
    if start_idx == -1:
        start_idx = 0  # ุงฺฏุฑ header ุญุฐู ุดุฏูุ ุงุฒ ุงุจุชุฏุง ุดุฑูุน ฺฉู
    
    # ูพุฏุง ฺฉุฑุฏู ูพุงุงู ุจุฎุด (ุดุฑูุน AD 2.13 ุง ูพุงุงู ูุชู)
    end_idx = text.find("AD 2.13", start_idx)
    if end_idx == -1:
        end_idx = len(text)
    
    ad2_12_text = text[start_idx:end_idx]
    
    # ุชูุณู ูุชู ุจู ุฎุทูุท
    lines = ad2_12_text.split('\n')
    
    # ูพุฏุง ฺฉุฑุฏู ุฏุงุฏูโูุง ุจุฎุด ุงูู (ุจุงูุฏูุง ุจุง ุฏุงุฏูโูุง ุณุชูู 1-6)
    # ุงูฺฏู: ุจุงูุฏ + TRUE BRG + Dimensions + Strength + Coordinates + THR elevation
    
    # ุฏุงุฏูโูุง ูุฑ ุจุงูุฏ ุฏุฑ ฺูุฏ ุฎุท ูุชูุงู ูุณุชูุฏ
    runway_data_part1 = []
    
    # ุงูฺฏู ุจุงูุฏ: ูุฑ ุจุงูุฏ ูุนุชุจุฑ (01L-36R)
    # ูุฑูุช: 11L 109.63GEO 3646 x 45 720/R/A/W/T 354144.03N THR 3956 FT
    runway_pattern = r'^(\d{2}[LRCM]?)\s+(\d+\.\d+)GEO\s+(\d+\s*x\s*\d+)\s+(\d+/[A-Z]/[A-Z]/[A-Z]/[A-Z])\s+(\d+\.?\d*[NS])\s+THR\s+(\d+)\s*FT'
    
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        
        # ุฌุณุชุฌู ุงูฺฏู ุจุงูุฏ ุฏุฑ ุฎุท
        match = re.match(runway_pattern, line)
        if match:
            rwy_nr = match.group(1)
            true_brg = match.group(2) + " GEO"
            dimensions = match.group(3)
            strength = match.group(4)
            thr_lat = match.group(5)
            thr_elev = "THR " + match.group(6) + " FT"
            
            # ุฎุท ุจุนุฏ: ุณุทุญ (Concrete/Asphalt) + ูุฎุชุตุงุช ุทูู ุฌุบุฑุงูุง
            surface = ""
            thr_lon = ""
            gund = ""
            
            if i + 1 < len(lines):
                next_line = lines[i + 1].strip()
                # ุงูฺฏู: Concrete/Asphalt + ูุฎุชุตุงุช
                surface_match = re.match(r'^(Concrete|Asphalt)\s+(\d+\.?\d*[EW])', next_line, re.IGNORECASE)
                if surface_match:
                    surface = surface_match.group(1)
                    thr_lon = surface_match.group(2)
                    i += 1
            
            # ุฎุท ุจุนุฏ: GUND
            if i + 1 < len(lines):
                gund_line = lines[i + 1].strip()
                gund_match = re.match(r'^GUND\s*([+-]?\d+)\s*FT', gund_line, re.IGNORECASE)
                if gund_match:
                    gund = "GUND " + gund_match.group(1) + "FT"
                    i += 1
            
            # ุณุงุฎุช ูุฎุชุตุงุช ฺฉุงูู
            thr_coordinates = f"{thr_lat} {thr_lon} {gund}".strip()
            
            # ุงุถุงูู ฺฉุฑุฏู ุณุทุญ ุจู strength
            if surface:
                strength = f"{strength} {surface}"
            
            # ุงฺฏุฑ ุงู ุจุงูุฏ ูุจูุงู ูุฌูุฏ ูุฏุงุฑุฏุ ุงุถุงูู ฺฉู
            if rwy_nr not in runways_dict:
                runways_dict[rwy_nr] = {
                    "Designations RWY NR": rwy_nr,
                    "TRUE BRG": true_brg,
                    "Dimensions of RWY": dimensions,
                    "Strength (PCR or PCN) and surface of RWY and SWY": strength,
                    "THR coordinates THR geoid undulation": thr_coordinates,
                    "THR elevation and highest elevation of TDZ of precision APP RWY": thr_elev,
                }
                runway_data_part1.append(runways_dict[rwy_nr])
                print(f"  โ ุจุงูุฏ {rwy_nr} ูพุฏุง ุดุฏ (ุจุฎุด 1)")
        
        i += 1
    
    # ูพุฏุง ฺฉุฑุฏู ุฏุงุฏูโูุง ุจุฎุด ุฏูู (ุณุชููโูุง 7-12)
    # ุงูฺฏู: Slope + SWY + CWY + Strip + RESA + OFZ
    
    # ูพุฏุง ฺฉุฑุฏู ุดุฑูุน ุจุฎุด ุฏูู (ุจุนุฏ ุงุฒ ุณุชููโูุง 7-12)
    part2_start = ad2_12_text.find("Slope of")
    if part2_start == -1:
        part2_start = ad2_12_text.find("7 8 9 10 11 12")
    
    if part2_start != -1:
        part2_text = ad2_12_text[part2_start:]
        part2_lines = part2_text.split('\n')
        
        # ุงูฺฏู ุฏุงุฏูโูุง ุจุฎุด ุฏูู
        # ูุฑ ุฎุท: Slope% + SWY + CWY + Strip + RESA + OFZ
        part2_pattern = r'^(\d+\.?\d*)\s*%\s+(NIL|\d+\s*x\s*\d+)\s+(NIL|\d+\s*x\s*\d+)\s+(NIL|\d+\s*x\s*\d+)\s+(NIL|\d+\s*x\s*\d+)\s+(NIL|[^\s]+)'
        
        runway_idx = 0
        processed_part2 = set()  # ุจุฑุง ุฌููฺฏุฑ ุงุฒ ูพุฑุฏุงุฒุด ุชฺฉุฑุงุฑ
        
        for line in part2_lines:
            line = line.strip()
            match = re.match(part2_pattern, line, re.IGNORECASE)
            if match and runway_idx < len(runway_data_part1):
                # ุจุฑุฑุณ ุชฺฉุฑุงุฑ ูุจูุฏู
                rwy_nr = runway_data_part1[runway_idx]["Designations RWY NR"]
                if rwy_nr in processed_part2:
                    continue
                
                slope = match.group(1) + "%"
                swy = clean_value(match.group(2))
                cwy = clean_value(match.group(3))
                strip = clean_value(match.group(4))
                resa = clean_value(match.group(5))
                ofz = clean_value(match.group(6))
                
                # ุงุถุงูู ฺฉุฑุฏู ุจู ุฏุงุฏูโูุง ุจุงูุฏ
                runway_data_part1[runway_idx]["Slope of RWY - SWY"] = slope
                runway_data_part1[runway_idx]["SWY dimensions"] = swy
                runway_data_part1[runway_idx]["CWY dimensions"] = cwy
                runway_data_part1[runway_idx]["Strip dimensions"] = strip
                runway_data_part1[runway_idx]["RESA"] = resa
                runway_data_part1[runway_idx]["OFZ"] = ofz
                
                processed_part2.add(rwy_nr)
                print(f"  โ ุจุงูุฏ {rwy_nr} ูพุฏุง ุดุฏ (ุจุฎุด 2)")
                
                runway_idx += 1
    
    # ุงุณุชุฎุฑุงุฌ ูุงุญุฏูุง ุงุฒ header ูุง
    # ูุงุญุฏูุง ูุนูููุงู ุฏุฑ ูพุฑุงูุชุฒ ูุณุชูุฏ: (M)
    units = extract_units_from_headers(ad2_12_text)
    
    # ุงุถุงูู ฺฉุฑุฏู ูุงุญุฏูุง ุจู ุฏุงุฏูโูุง (Case sensitive)
    for runway in runway_data_part1:
        for field_name, unit in units.items():
            if field_name in runway and runway[field_name] is not None:
                runway[f"{field_name}_unit"] = unit
    
    # ูุฑุชุจโุณุงุฒ ููุฏูุง ุฏุฑ ุชุฑุชุจ ุตุญุญ
    field_order = [
        "Designations RWY NR",
        "TRUE BRG",
        "Dimensions of RWY",
        "Dimensions of RWY_unit",
        "Strength (PCR or PCN) and surface of RWY and SWY",
        "THR coordinates THR geoid undulation",
        "THR elevation and highest elevation of TDZ of precision APP RWY",
        "Slope of RWY - SWY",
        "SWY dimensions",
        "SWY dimensions_unit",
        "CWY dimensions",
        "CWY dimensions_unit",
        "Strip dimensions",
        "Strip dimensions_unit",
        "RESA",
        "RESA_unit",
        "OFZ",
    ]
    
    sorted_runways = []
    for runway in runway_data_part1:
        sorted_runway = {}
        for field in field_order:
            if field in runway:
                sorted_runway[field] = runway[field]
        # ุงุถุงูู ฺฉุฑุฏู ููุฏูุง ฺฉู ุฏุฑ ูุณุช ูุณุชูุฏ
        for field in runway:
            if field not in sorted_runway:
                sorted_runway[field] = runway[field]
        sorted_runways.append(sorted_runway)
    
    return sorted_runways


def extract_units_from_headers(text: str) -> dict:
    """
    ุงุณุชุฎุฑุงุฌ ูุงุญุฏูุง ุงุฒ header ูุง ุฌุฏูู (Case sensitive)
    """
    units = {}
    
    # ุงูฺฏููุง ูุงุญุฏ ุฏุฑ header ูุง
    # ุฌุณุชุฌู ุฏุฑ ูุชู ุจุฑุง ุงูุชู ูุงุญุฏูุง ุฏุฑ ูพุฑุงูุชุฒ
    unit_patterns = {
        "Dimensions of RWY": r"RWY\s*\(([A-Za-z]+)\)",
        "SWY dimensions": r"SWY[^\n]*?\(([A-Za-z]+)\)",
        "CWY dimensions": r"CWY[^\n]*?\(([A-Za-z]+)\)",
        "Strip dimensions": r"Strip[^\n]*?\(([A-Za-z]+)\)",
        "RESA": r"RESA[^\n]*?\(([A-Za-z]+)\)",
    }
    
    for field_name, pattern in unit_patterns.items():
        match = re.search(pattern, text)  # Case sensitive
        if match:
            units[field_name] = match.group(1)  # Case sensitive - ูุซูุงู M
    
    # ุงฺฏุฑ ูุงุญุฏูุง ูพุฏุง ูุดุฏูุฏุ ุงุฒ ููุงุฏุฑ ูพุดโูุฑุถ ุงุณุชูุงุฏู ูโฺฉูู
    # ุจุฑ ุงุณุงุณ ุงุณุชุงูุฏุงุฑุฏ AIPุ ูุงุญุฏ ุงุจุนุงุฏ M (ูุชุฑ) ุงุณุช
    default_units = {
        "Dimensions of RWY": "M",
        "SWY dimensions": "M",
        "CWY dimensions": "M",
        "Strip dimensions": "M",
        "RESA": "M",
    }
    
    for field_name, default_unit in default_units.items():
        if field_name not in units:
            units[field_name] = default_unit
    
    return units


def main():
    """ุชุงุจุน ุงุตู"""
    if len(sys.argv) > 1:
        pdf_path = sys.argv[1]
    else:
        pdf_path = "OIII.pdf"
    
    if not Path(pdf_path).exists():
        print(f"โ ูุงู PDF ุงูุช ูุดุฏ: {pdf_path}")
        sys.exit(1)
    
    # ุงุณุชุฎุฑุงุฌ ุฏุงุฏูโูุง
    try:
        data = extract_ad2_12(pdf_path)
        
        if not data:
            print("โ ูฺ ุฏุงุฏูโุง ุงุณุชุฎุฑุงุฌ ูุดุฏ!")
            sys.exit(1)
        
        # ุฐุฎุฑู ุฏุฑ ูุงู JSON
        output_path = "ad2_12_output.json"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"\nโ ุงุณุชุฎุฑุงุฌ ุจุง ููููุช ุงูุฌุงู ุดุฏ!")
        print(f"๐ ูุงู ุฎุฑูุฌ: {output_path}")
        print(f"๐ ุชุนุฏุงุฏ ุจุงูุฏูุง ุงุณุชุฎุฑุงุฌ ุดุฏู: {len(data)}")
        print("\n๐ ุฏุงุฏูโูุง ุงุณุชุฎุฑุงุฌ ุดุฏู:")
        
        for i, runway in enumerate(data, 1):
            print(f"\n  ุจุงูุฏ {i}: {runway.get('Designations RWY NR', 'N/A')}")
            for key, value in runway.items():
                if key != "Designations RWY NR":
                    display_value = str(value)[:70] + "..." if len(str(value)) > 70 else value
                    print(f"    โข {key}: {display_value}")
        
    except Exception as e:
        print(f"\nโ ุฎุทุง ุฏุฑ ูพุฑุฏุงุฒุด: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
